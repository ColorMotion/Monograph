\documentclass[12pt,openright,twoside,a4paper,english]{abntex2}
\selectlanguage{english}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{capa-epusp-abntex2/capa-epusp-abntex2}  % ver https://github.com/brunocfp/capa-epusp-abntex2/blob/master/README.md
% Folha de estilo: http://www.poli.usp.br/bibliotecas/servicos/publicacoes-online.html
% http://pro.poli.usp.br/wp-content/uploads/2012/04/NGTF2017.pdf
% http://www.poli.usp.br/images/stories/media/download/bibliotecas/DiretrizesTesesDissertacoes.pdf
% http://sites.poli.usp.br/d/pme2599/Documentos/Diretrizes%20de%20elabora%C3%A7%C3%A3o%20do%20trabalho%20final.pdf
\usepackage[alf]{abntex2cite}	% Citações padrão ABNT

\author{TIAGO KOJI CASTRO SHIBATA\\
HENRIQUE CASSIANO SOUZA BARROS\\
VICTORIA AKINA TANAKA}
\orientador{BRUNO DE CARVALHO ALBERTINI}
\areaconcentracao{Computer Engineering}
\preambulo{Monograph of the capstone project for the Computer Engineering bachelor in Escola Politécnica da Universidade de São Paulo}
\title{ColorMotion: Automatic video colorization}
\date{São Paulo\\(November 2018)}

\begin{document}
\begin{otherlanguage}{english}

\imprimircapa
\imprimirfalsafolhaderosto
\imprimirfolhaderosto

\begin{epigrafe}
\begin{flushright}
\vspace*{\fill}
\textit{``It is the supreme art of the teacher to awaken joy in creative expression and knowledge``}\\
(Albert Einstein)
\par
\end{flushright}
\end{epigrafe}

\begin{resumo}
Deep learning has been applied to a wide spectrum of fields successfully.
\vspace{\onelineskip}

\noindent
\textbf{Keywords}: Engineering. Capstone. Colorization. Potato salad.
\end{resumo}

TODO listas de gráficos, tabelas, abreviaturas e siglas, símbolos

\tableofcontents

\maketitle

\chapter{Introduction}
\section{Introduction}

\subsection{Objective}
In this paper, we propose a method for automatic video colorization, using a machine learning-based approach.

\subsection{Motivation} \label{sec:Motivation}
The problem of colorization in the field of machine learning is one of major interest, as exemplifies key aspects in machine learning applications involving classification. It also presents results that can be easily compared to human perception and performance, and can be used to automate a manual process. The algorithms in the field focus on the coloring of images, with colorization of videos being a extension or proposed continuation. We propose the use of state-of-the-art machine learning algorithms to colorize videos, prioritizing methods to maintain consistency of colors between frames in a scene whilst detecting frames associated with a new scene.

\subsection{Justification}
As stated in section \ref{sec:Motivation}, the traditional process of coloring images involve manual inputs from the user, with the authenticity of the expected coloring being a major limiting aspect.
%TODO: citation needed, problaly something about restoring pictures
The same can be said to the colorization of videos, with the added difficulty of maintaining consistency through frames. Some editing tools can help this process by tracking the input from the user between frames, but the initial input and challenges involving rapid changing scenes add to the complexity of the process.
%TODO: citation needed, falar dos editores?

\chapter{Literature review}

1) Levantamento bibliográfico em bases de dados nacionais e internacionais, a
partir de palavras-chave em português e inglês;

2) Busca pelos textos completos dos trabalhos selecionados no levantamento;

3) Leitura e fichamento (resumo analítico) dos trabalhos relevantes. É imprescindível anotar os dados dos documentos consultados, para posterior citação e referência;

4) Cruzamento de informações e citações de modo a elencar um quadro de autores sobre o assunto, alinhados com o ponto de vista do pesquisador;

5) Redação da revisão e citações, de acordo com o assunto e tópicos abordados.

A learning-based approach for automatic image and video colorization

\chapter{Methodology}
\subsection{Organization?}
TODO

\section{Conceptual aspects} \label{sec:Concept}
Neural networks for colorization can be divided in two broad categories: those that require a input from the user, and those that use a automated process. In both cases, the most common approach uses Convolutional Neural Networks (CNN) to leverage different image characteristics, and use those patterns to identify and separate objects in the image and colorize them accordingly. Other approaches are possible, for example through the use of self organizing maps along side neural networks as shown in Richart \textit{et al.} \cite{Richart_som_nn}; but for the purposes of this paper we will focus in CNN-based algorithms.

User guided algorithms TODO

\section{Methodology}
The methodology adopted four main phases of development: study and choice of existent machine learning algorithms; development of a dataset; adaptation of the chosen algorithm to support recurrent frame inputs and optical flow patterns; and optimization based on A/B tests and metrics.

\subsection{choice of algorithm}
Like stated on section \ref{sec:Concept}, the

\subsection{dataset}
Preparation:

TODO Histogram and SSIM analysis

Augmentation:

TODO document Keras augmentation

The initial dataset was composed of the free movies Tears of Steel (year TODO cite) and Valkaama (year TODO cite). After filtering and splitting the scenes, the dataset had 142753 frames in 836 distinct scenes. This dataset proved too small for the task in hand, given that, in our methodology, we employed a network with a high number of parameters, which is very prone to overfitting. The network did overfit in our initial tests (TODO train/val numbers and curve).

The dataset was enlarged with videos from the free video repository Pixabay, under the Creative Commons licence, and from videos in the author's personal archives. The enlarged dataset has 591780 frames in distinct 1629 scenes. Data augmentation was also implemented during training to reduce the amount of overfitting to the training dataset. TODO document augmentation. TODO show reduced overfitting, show loss curves.

Lastly, part of the ImageNet (ref: http://image-net.org/about-overview) dataset was downloaded from the URLs provided in the ImageNet website. The dataset has a variety of pictures belonging to one of thousands of "synonym sets". 795881 (TODO: update number) images were used during training of the user guided colorization model.

\subsection{algorithm adaptation}

\subsection{optimization}
After obtaining a network that can adequately process a video with

TODO strategy: incremental enhancements and retraining, document importing weights from other models, document performance optimizations

\section{Used technologies}
The implementation of

\section{System specifications}
TODO specs, performance analisys

\chapter{Results}

\chapter{Discussion of achieved results}

\chapter{Conclusions}

\chapter{TODO glossary, appendix}

\bibliography{referencias.bib}
%\printbibliography

\end{otherlanguage}
\end{document}
